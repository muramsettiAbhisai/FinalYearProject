import torch
import torch.nn as nn
import torchvision.models as models

class ConvBNReLU(nn.Module):
    def __init__(self, c_in, c_out, kernel_size, stride=1, padding=1, activation=True):
        super(ConvBNReLU, self).__init__()
        self.conv = nn.Conv2d(c_in, c_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)
        self.bn = nn.BatchNorm2d(c_out)
        self.relu = nn.LeakyReLU(inplace=True)
        self.activation = activation

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        if self.activation:
            x = self.relu(x)
        return x

class DoubleConv(nn.Module):
    def __init__(self, cin, cout):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            ConvBNReLU(cin, cout, 3, 1, padding=1),
            ConvBNReLU(cout, cout, 3, stride=1, padding=1, activation=False))
        self.conv1 = nn.Conv2d(cout, cout, 1)
        self.relu = nn.ReLU()
        self.bn = nn.BatchNorm2d(cout)

    def forward(self, x):
        x = self.conv(x)
        h = x
        x = self.conv1(x)
        x = self.bn(x)
        x = h + x
        x = self.relu(x)
        return x

class MTUNet(nn.Module):
    def __init__(self, out_ch=4):
        super(MTUNet, self).__init__()
        
        # Encoder
        self.enc1 = DoubleConv(3, 64)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = DoubleConv(64, 128)
        self.pool2 = nn.MaxPool2d(2)
        self.enc3 = DoubleConv(128, 256)
        self.pool3 = nn.MaxPool2d(2)
        self.enc4 = DoubleConv(256, 512)
        self.pool4 = nn.MaxPool2d(2)
        
        # Bottleneck
        self.bottleneck = DoubleConv(512, 1024)
        
        # Attention gates
        self.attention1 = AttentionGate(512, 1024, 512)
        self.attention2 = AttentionGate(256, 512, 256)
        self.attention3 = AttentionGate(128, 256, 128)
        self.attention4 = AttentionGate(64, 128, 64)
        
        # Decoder
        self.up1 = nn.ConvTranspose2d(1024, 512, 2, stride=2)
        self.dec1 = DoubleConv(1024, 512)
        self.up2 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.dec2 = DoubleConv(512, 256)
        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec3 = DoubleConv(256, 128)
        self.up4 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec4 = DoubleConv(128, 64)
        
        # Output layer
        self.out = nn.Conv2d(64, out_ch, 1)
        
        # Multi-scale feature extraction
        self.context_block = ContextBlock(64, 64)

    def forward(self, x):
        if x.size()[1] == 1:
            x = x.repeat(1, 3, 1, 1)
        
        # Encoder
        e1 = self.enc1(x)
        p1 = self.pool1(e1)
        e2 = self.enc2(p1)
        p2 = self.pool2(e2)
        e3 = self.enc3(p2)
        p3 = self.pool3(e3)
        e4 = self.enc4(p3)
        p4 = self.pool4(e4)
        
        # Bottleneck
        b = self.bottleneck(p4)
        
        # Attention mechanisms
        a4 = self.attention1(e4, b)
        a3 = self.attention2(e3, a4)
        a2 = self.attention3(e2, a3)
        a1 = self.attention4(e1, a2)
        
        # Decoder
        u1 = self.up1(b)
        c1 = torch.cat((u1, a4), dim=1)
        d1 = self.dec1(c1)
        
        u2 = self.up2(d1)
        c2 = torch.cat((u2, a3), dim=1)
        d2 = self.dec2(c2)
        
        u3 = self.up3(d2)
        c3 = torch.cat((u3, a2), dim=1)
        d3 = self.dec3(c3)
        
        u4 = self.up4(d3)
        c4 = torch.cat((u4, a1), dim=1)
        d4 = self.dec4(c4)
        
        d4 = self.context_block(d4)
        
        out = self.out(d4)
        return out

class AttentionGate(nn.Module):
    def __init__(self, x_channels, g_channels, out_channels):
        super(AttentionGate, self).__init__()
        self.W_g = nn.Sequential(
            nn.Conv2d(g_channels, out_channels, 1, 1, 0, bias=True),
            nn.BatchNorm2d(out_channels)
        )
        self.W_x = nn.Sequential(
            nn.Conv2d(x_channels, out_channels, 1, 1, 0, bias=True),
            nn.BatchNorm2d(out_channels)
        )
        self.psi = nn.Sequential(
            nn.Conv2d(out_channels, 1, 1, 1, 0, bias=True),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x, g):
        if g.size()[2:] != x.size()[2:]:
            g = nn.functional.interpolate(g, size=x.size()[2:], mode='bilinear', align_corners=True)
        psi = self.relu(self.W_g(g) + self.W_x(x))
        psi = self.psi(psi)
        return x * psi

class ContextBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ContextBlock, self).__init__()
        self.conv_att = nn.Conv2d(in_channels, in_channels//2, 1)
        self.gap = nn.AdaptiveAvgPool2d(1)
        self.sigmoid = nn.Sigmoid()
        self.conv1 = nn.Conv2d(in_channels, out_channels, 1)
        self.conv3 = nn.Conv2d(in_channels, out_channels, 3, padding=1)
        self.conv5 = nn.Conv2d(in_channels, out_channels, 5, padding=2)
        self.conv_fusion = nn.Conv2d(3*out_channels, out_channels, 1)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        att = self.sigmoid(self.conv_att(self.gap(x)))
        feat_cat = torch.cat([self.conv1(x), self.conv3(x), self.conv5(x)], dim=1)
        out = self.relu(self.bn(self.conv_fusion(feat_cat)))
        return out
